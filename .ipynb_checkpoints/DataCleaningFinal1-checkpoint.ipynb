{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "import difflib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MVA(years):\n",
    "    col_name = [\"COLLISION_DATE\",\"COLLISION_TIME\",\"PRIMARY_RD\",\"SECONDARY_RD\",\"CHP_BEAT_TYPE\",\"WEATHER_1\",\"COLLISION_SEVERITY\",\"PRIMARY_COLL_FACTOR\",\"PCF_VIOL_CATEGORY\",\"LIGHTING\",\"ROAD_SURFACE\",\"ROAD_COND_1\"]\n",
    "    MVA_DF = pd.DataFrame(data=None, index=None, columns=col_name, dtype=None) #New empty dataframe\n",
    "    MVA_DF_2015 = pd.DataFrame(data=None, index=None, columns=col_name, dtype=None) #New empty dataframe\n",
    "    size=0\n",
    "    for year in years:\n",
    "        if (year != 2012) : \n",
    "            DF = pd.read_csv('CollisionRecords%i.txt' % year,sep = ',', dtype='unicode') #Read the csv file\n",
    "            DF = DF[col_name]\n",
    "            DF = cleaning_MVA(DF)\n",
    "            size += len(DF) #Check size matches \n",
    "            if year >= 2015 : \n",
    "                MVA_DF_2015 = MVA_DF_2015.append(DF)#Add DF to our initialized dataframe\n",
    "            else : \n",
    "                MVA_DF = MVA_DF.append(DF)#Add DF to our initialized dataframe\n",
    "\n",
    "            \n",
    "    print(size)#Just to check\n",
    "    return(MVA_DF,MVA_DF_2015)\n",
    "\n",
    "def OCI(year_oci):\n",
    "    dct_oci = {2011: 'DF_OCI_2011', 2015: 'DF_OCI_2011'}\n",
    "    for year in year_oci : \n",
    "        dct_oci[year] = pd.read_csv('OCI_SD_%i.csv' % year,sep = ',', dtype='unicode') #Read the csv file\n",
    "        dct_oci[year]= dct_oci[year][['oci','street','street_from','street_to','oci_desc']] #Keep only relevant variables\n",
    "    return(dct_oci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning_MVA(MVA_DF):\n",
    "    print(\"original size : \", len(MVA_DF))\n",
    "    MVA_DF= MVA_DF.reset_index(drop=True)\n",
    "    reg = re.compile(\"((.*)?I(-|\\s)?(-|\\s)?\\d+)(.*)?|(.*)?((S|R)(.)?(R|T)(.)?(\\s)?\\d+)(.*)?\")\n",
    "    count = 0\n",
    "    pattern_digitAV = re.compile(\"^(^[0-9])([A-Z].*)\") #If start with one digit and followed by str\n",
    "    dico = {\"HWY\" : \"HY\", \"RT \" : \"I-\",\"INTERSTATE \": \"I-\",\"STATE ROUTE \": \"I-\",\"STREET\": \"ST\",\"AVENUE\":\"AV\",\"AVE\":\"AV\",\"EAST\": \"E\",\"WEST\":\"W\",\"NORTH\":\"N\",\"SOUTH\":\"S\"} \n",
    "    for i in range(len(MVA_DF)) : #When finished, len(DF)\n",
    "        (MVA_DF[\"PRIMARY_RD\"])[i] = multiple_replace(dico,(MVA_DF[\"PRIMARY_RD\"])[i]) #Get the street name\n",
    "        (MVA_DF[\"SECONDARY_RD\"])[i] = multiple_replace(dico,(MVA_DF[\"SECONDARY_RD\"])[i]) #Get intersection \n",
    "        digit_AV_street = pattern_digitAV.match((MVA_DF[\"PRIMARY_RD\"])[i]) # Check if match with pattern\n",
    "        digit_AV_Inter =pattern_digitAV.match((MVA_DF[\"SECONDARY_RD\"])[i]) # Check if match with pattern\n",
    "        if digit_AV_Inter is not None : \n",
    "            (MVA_DF[\"SECONDARY_RD\"])[i]= \"0\" + digit_AV_Inter.group()    #Add a 0 in front if match\n",
    "        if digit_AV_street is not (None):\n",
    "            (MVA_DF[\"PRIMARY_RD\"])[i] = \"0\" + digit_AV_street.group() #Add a 0 in front if match\n",
    "        if reg.match((MVA_DF[\"PRIMARY_RD\"])[i]):\n",
    "            MVA_DF.drop(i, inplace=True)\n",
    "            count = count+1\n",
    "    MVA_DF = MVA_DF.loc[MVA_DF.PCF_VIOL_CATEGORY != '1'] #If driving under drugs or alcohol\n",
    "    print(\"count\",count)\n",
    "    print(\"lenDF: \",len(MVA_DF))\n",
    "    return (MVA_DF)\n",
    "\n",
    "def multiple_replace(dico, name_street):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dico.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return (regex.sub(lambda mo: dico[mo.string[mo.start():mo.end()]], name_street) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def street_match(MVA_DF,DF_OCI):\n",
    "    print('Je suis la')\n",
    "    DF = pd.DataFrame(data=None, index=None, columns= None, dtype=None) #Will be final merged DF\n",
    "    street_len = 0 #Var for number of Primary_RD not matching street name\n",
    "    intersection_len = 0 #Var for number of Secondary_RD not matching street_from or street_to\n",
    "    MVA_DF= MVA_DF.reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(MVA_DF)) : #Loop through all the DF with the Accidents/Collisison\n",
    "        street_name = (MVA_DF[\"PRIMARY_RD\"])[i] #Get street_name from Primary_RD\n",
    "        intersection = (MVA_DF[\"SECONDARY_RD\"])[i] #Get the Secondary_RD/Intersection \n",
    "        TEMP = DF_OCI.loc[(DF_OCI['street'].str.contains(street_name))] #Get all the street in the OCI that contains or is equal to street_name (from MVA_DF)    \n",
    "        if TEMP.empty: #If nothing matchs\n",
    "            street_len = street_len +1\n",
    "            Close_Match_Street = (difflib.get_close_matches(street_name, (DF_OCI['street']),n=1)) #Function that finds the closest match - Chose to only take one out of the different matches\n",
    "            if (Close_Match_Street != []) : #If there is a match\n",
    "                TEMPA = DF_OCI.loc[DF_OCI['street'].str.contains(Close_Match_Street[0])] #Get all the street names from DF_OCI that contain or is equal to this new close match\n",
    "                TEMP3,intersection_len= inter(TEMPA,intersection_len,intersection,i)\n",
    "                if not TEMP3.empty : \n",
    "                    DF = dataframe(TEMP3,i,DF,MVA_DF)\n",
    "            else :\n",
    "                print(\"No street match\")\n",
    "                print(\"Street : \",street_name,\" Intersection : \",intersection)        \n",
    "        else : \n",
    "            TEMP2,intersection_len= inter(TEMP,intersection_len,intersection,i) \n",
    "            DF= dataframe(TEMP2,i,DF,MVA_DF)\n",
    "\n",
    "        print(i)\n",
    "        \n",
    "    return(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inter(TEMP,intersection_len,intersection,i) : \n",
    "    TEMP2 = pd.DataFrame(data=None, index=None, columns= None, dtype=None) #New empty dataframe    \n",
    "    TEMP2 = TEMP.loc[(TEMP['street_from'] == intersection)|(TEMP['street_to']==(intersection))]  \n",
    "    if TEMP2.empty : \n",
    "        Close_Match_Intersection = (difflib.get_close_matches(intersection, (TEMP['street_from']),n=1))\n",
    "        Close_Match_To = (difflib.get_close_matches(intersection, (TEMP['street_to']),n=1))\n",
    "        if (Close_Match_Intersection != []) & (Close_Match_To != []) : \n",
    "            TEMP2 = TEMP.loc[(TEMP['street_from'] == Close_Match_Intersection[0])|(TEMP['street_to']== Close_Match_To[0])]\n",
    "        elif (Close_Match_Intersection != []) : \n",
    "            TEMP2 = TEMP.loc[(TEMP['street_from'] == Close_Match_Intersection[0])]\n",
    "        elif (Close_Match_To != []) : \n",
    "            TEMP2 = TEMP.loc[(TEMP['street_to'] == Close_Match_To[0])]\n",
    "        else : \n",
    "            #print(\"Street : \",street_name,\" Intersection : \",intersection,\"INDEX : \",i)\n",
    "            intersection_len = intersection_len +1\n",
    "    if TEMP2 is not None : \n",
    "        return(TEMP2,intersection_len)\n",
    "    \n",
    "def dataframe(TEMP,i,DF,MVA_DF):\n",
    "    TEST = pd.DataFrame(data=None, index=None, columns= None, dtype=None)\n",
    "    TEMP = TEMP.reset_index(drop=True)#From OCI DF\n",
    "    TEMP1 = MVA_DF.loc[MVA_DF.index == i]\n",
    "    TEMP1 = TEMP1.reset_index(drop=True)\n",
    "    a = True\n",
    "    length = len(TEMP)\n",
    "    if length ==1 :\n",
    "        TEST = TEMP.join(TEMP1)\n",
    "        DF = DF.append(TEST) \n",
    "    elif length > 1 : \n",
    "        for j in range(len(TEMP)-1) :\n",
    "            if (TEMP['oci_desc'])[j] != (TEMP['oci_desc'])[j+1]:\n",
    "                a = False\n",
    "        if a == True : \n",
    "            TEMP = TEMP.loc[[0]]\n",
    "            TEST = TEMP.join(TEMP1)\n",
    "            DF = DF.append(TEST)\n",
    "    if DF is not None :\n",
    "        return(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save(DF,name) : \n",
    "    DF= DF.reset_index(drop=True)\n",
    "    DF.to_csv('%s.csv' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size :  7840\n",
      "count 3808\n",
      "lenDF:  4032\n",
      "original size :  8858\n",
      "count 4920\n",
      "lenDF:  3938\n",
      "original size :  9503\n",
      "count 5102\n",
      "lenDF:  4401\n",
      "original size :  10075\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    years = [2011,2013,2014,2015]\n",
    "    MVA_1,MVA_2 = MVA(years)\n",
    "    OCI_1 = OCI([2011,2015])\n",
    "    DF_1 = street_match(MVA_1,OCI_1[2011])\n",
    "    DF_2= street_match(MVA_2,OCI_1[2015])\n",
    "    save(DF_1,'DF_1')\n",
    "    save(DF_2,'DF_2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(DF) : \n",
    "#LIGHT = DF['LIGHTING'].loc[(DF.LIGHTING == 'A')| (DF.LIGHTING == 'B')]\n",
    "    DF['LIGHTING'].loc[(DF.LIGHTING == 'A')| (DF.LIGHTING == 'B')] = np.random.randint(70,100, len(DF['LIGHTING'].loc[(DF.LIGHTING == 'A')| (DF.LIGHTING == 'B')]))\n",
    "    DF['LIGHTING'].loc[(DF.LIGHTING == 'E')| (DF.LIGHTING == 'D')] = np.random.randint(0,40, len(DF['LIGHTING'].loc[(DF.LIGHTING == 'E')| (DF.LIGHTING == 'D')]))\n",
    "    DF['LIGHTING'].loc[(DF.LIGHTING == 'C')] = np.random.randint(40,70, len(DF['LIGHTING'].loc[(DF.LIGHTING == 'C')]))\n",
    "\n",
    "    DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'B')| (DF.WEATHER_1 == 'A')] = np.random.randint(70,100, len(DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'A')| (DF.WEATHER_1 == 'B')]))\n",
    "    DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'G')] = np.random.randint(40,70, len(DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'G')]))\n",
    "    DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'E')| (DF.WEATHER_1 == 'C')] = np.random.randint(0,40, len(DF['WEATHER_1'].loc[(DF.WEATHER_1 == 'C')| (DF.WEATHER_1 == 'E')]))\n",
    "    return (DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "#DF = pd.read_csv('DF_1.csv',sep = ',', dtype='unicode',index_col=0) #Read the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_1 = pd.read_csv('DF_1.csv',sep = ',', dtype='unicode',index_col=0) #Read the csv file\n",
    "DF_2 = pd.read_csv('DF_2.csv',sep = ',', dtype='unicode',index_col=0) #Read the csv file\n",
    "DF_1 = transform(DF_1)\n",
    "DF_2 = transform(DF_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL = pd.read_csv('LL.csv',sep = ',', dtype='unicode',index_col=0)#0 to 615\n",
    "LL2 =pd.read_csv('LL2.csv',sep = ',', dtype='unicode',index_col=0)#630 to 2000\n",
    "LL3= pd.read_csv('LL3.csv',sep = ',', dtype='unicode',index_col=0)#2000 to 4000\n",
    "LL4= pd.read_csv('LL4.csv',sep = ',', dtype='unicode',index_col=0)#4000 to end\n",
    "LL5= pd.read_csv('LL5.csv',sep = ',', dtype='unicode',index_col=0)#615 to 630 \n",
    "\n",
    "A = LL5.append(LL2.append(LL3.append(LL4)))\n",
    "L1 = LL.loc[LL.LAT !='1.0']\n",
    "TEMP_LL = DF_1[:len(L1)].join(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEMP_DF = DF_1.loc[DF_1.index >=615]\n",
    "TEMP_LL2 = TEMP_DF.reset_index(drop=True)[:len(A)].join(A.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_LL = TEMP_LL.append(TEMP_LL2).reset_index(drop=True)\n",
    "Final_LL['LAT'] = pd.to_numeric(Final_LL['LAT'],downcast='float')\n",
    "Final_LL['LONG']=(pd.to_numeric(Final_LL['LONG'],downcast='float'))\n",
    "Final_LL['oci']=(pd.to_numeric(Final_LL['oci'],downcast='float'))\n",
    "len(Final_LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "\n",
    "# read the in the shapefile and list the methods associated with the object\n",
    "sf = shapefile.Reader(\"ZillowNeighborhoods-CA.shp\")\n",
    "#dir(sf)\n",
    "sfdbf = shapefile.Reader(\"ZillowNeighborhoods-CA.dbf\")\n",
    "metadata = sfdbf.shapeRecords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def marker(name,pos,liste,color):\n",
    "    #print(color)\n",
    "    kw = dict(fill_color=color, radius=4)\n",
    "    name = folium.CircleMarker(pos, **kw)\n",
    "    liste.append(name)\n",
    "    return (liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "#PB : westlimit=-117.262754; southlimit=32.778778; eastlimit=-117.209155; northlimit=32.823234\n",
    "#GASLAMP : westlimit=-117.165607; southlimit=32.706695; eastlimit=-117.159224; northlimit=32.71568\n",
    "\n",
    "PBW=-117.262754; PBS=32.778778; PBE=-117.209155; PBN=32.823234\n",
    "GW=-117.165607; GS=32.706695; GE=-117.159224; GN=32.71568\n",
    "LFair= Final_LL.loc[Final_LL.oci_desc == 'Fair']\n",
    "LPoor= Final_LL.loc[Final_LL.oci_desc == 'Poor']\n",
    "LGood= Final_LL.loc[Final_LL.oci_desc == 'Good']\n",
    "lat = 32.8811\n",
    "lon = -117.2375\n",
    "L = [LPoor,LFair,LGood]\n",
    "liste= []\n",
    "a = 0\n",
    "dic_color = {0:'red',1:'blue',2: 'green'}\n",
    "for FPG in L : \n",
    "    print(a)\n",
    "    for i in FPG.index :\n",
    "        name = 'pos' + str(i)\n",
    "        pos = [Final_LL.LAT[i], Final_LL.LONG[i]]\n",
    "        if (GS < float(Final_LL.LAT[i]) < GN) & (GW < float(Final_LL.LONG[i]) < GE) : \n",
    "            print('GASLAMP AREA',pos)\n",
    "            liste= marker(name,pos,liste,dic_color[a])\n",
    "        if (PBS < float(Final_LL.LAT[i]) < PBN) & (PBW < float(Final_LL.LONG[i]) <PBE ):\n",
    "            print('PB',pos)\n",
    "            liste= marker(name,pos,liste,dic_color[a])\n",
    "        name = 'pos' + str(i)\n",
    "        zoom_start = 10\n",
    "        m = folium.Map(location=[lat, lon], zoom_start=zoom_start)\n",
    "        #liste= marker(name,pos,liste,color)\n",
    "    a +=1\n",
    "    \n",
    "GW=-117.165607; GS=32.706695; GE=-117.159224; GN=32.71568\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in liste:\n",
    "    m.add_child(c)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "#PB : westlimit=-117.262754; southlimit=32.778778; eastlimit=-117.209155; northlimit=32.823234\n",
    "#GASLAMP : westlimit=-117.165607; southlimit=32.706695; eastlimit=-117.159224; northlimit=32.71568\n",
    "\n",
    "PBW=-117.262754; PBS=32.778778; PBE=-117.209155; PBN=32.823234\n",
    "GW=-117.165607; GS=32.706695; GE=-117.159224; GN=32.71568\n",
    "LFair= Final_LL.loc[Final_LL.oci_desc == 'Fair']\n",
    "LPoor= Final_LL.loc[Final_LL.oci_desc == 'Poor']\n",
    "LGood= Final_LL.loc[Final_LL.oci_desc == 'Good']\n",
    "lat = 32.8811\n",
    "lon = -117.2375\n",
    "L = [LPoor,LFair,LGood]\n",
    "liste= []\n",
    "a = 0\n",
    "dic_color = {0:'red',1:'blue',2: 'green'}\n",
    "for FPG in L : \n",
    "    print(a)\n",
    "    for i in FPG.index :\n",
    "        name = 'pos' + str(i)\n",
    "        pos = [Final_LL.LAT[i], Final_LL.LONG[i]]\n",
    "        if (GS < float(Final_LL.LAT[i]) < GN) & (GW < float(Final_LL.LONG[i]) < GE) : \n",
    "            print('GASLAMP AREA',pos)\n",
    "            liste= marker(name,pos,liste,dic_color[a])\n",
    "        if (PBS < float(Final_LL.LAT[i]) < PBN) & (PBW < float(Final_LL.LONG[i]) <PBE ):\n",
    "            print('PB',pos)\n",
    "            liste= marker(name,pos,liste,dic_color[a])\n",
    "        name = 'pos' + str(i)\n",
    "        zoom_start = 10\n",
    "        m = folium.Map(location=[lat, lon], zoom_start=zoom_start)\n",
    "        #liste= marker(name,pos,liste,color)\n",
    "    a +=1\n",
    "    \n",
    "GW=-117.165607; GS=32.706695; GE=-117.159224; GN=32.71568\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Regional differences - Comparison between PB and Gaslamp - Should do a t_test or chi square !\n",
    "\n",
    "PB_DF = Final_LL.loc[(Final_LL.LAT <= PBN)& (Final_LL.LAT >= PBS)& (Final_LL.LONG >= PBW )& (Final_LL.LONG <= PBE)]\n",
    "GS_DF = Final_LL.loc[(Final_LL.LAT <= GN) & (Final_LL.LAT >= GS) & (Final_LL.LONG >= GW )& (Final_LL.LONG <= GE)]\n",
    "PB_DF = PB_DF.dropna()\n",
    "GS_DF= GS_DF.dropna()\n",
    "size_fair_pb = len(PB_DF.loc[PB_DF.oci_desc == 'Fair'])/len(PB_DF)*10\n",
    "size_poor_pb = len(PB_DF.loc[PB_DF.oci_desc == 'Poor'])/len(PB_DF)*10\n",
    "size_good_pb = len(PB_DF.loc[PB_DF.oci_desc == 'Good'])/len(PB_DF)*10\n",
    "\n",
    "size_fair_gas = len(GS_DF.loc[GS_DF.oci_desc == 'Fair'])/len(GS_DF)*10\n",
    "size_poor_gas = len(GS_DF.loc[GS_DF.oci_desc == 'Poor'])/len(GS_DF)*10\n",
    "size_good_gas = len(GS_DF.loc[GS_DF.oci_desc == 'Good'])/len(GS_DF)*10\n",
    "\n",
    "dic_size_gas = {0: [size_poor_gas,'red'],1:[size_fair_gas,'purple'],2 : [size_good_gas,'blue']}\n",
    "dic_size_PB = {0: [size_poor_pb,'red'],1:[size_fair_pb,'purple'],2 : [size_good_pb,'blue']}\n",
    "print('GASLAMP DATA')\n",
    "dic_size_gas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('PB DATA')\n",
    "dic_size_PB\n",
    "PB_DF['oci_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "#Stats testing for OCI/MVA of PB vs Gaslamp ; PB vs All SD and Gaslamp vs all SD (only the 2 last are significant !!) \n",
    "s,p_PBVSGS = stats.ttest_ind(PB_DF['oci'],GS_DF['oci'])\n",
    "s1,p_PBVSTOT = stats.ttest_ind(PB_DF['oci'],Final_LL['oci'])\n",
    "s2,p_GSVSTOT = stats.ttest_ind(Final_LL['oci'],GS_DF['oci'])\n",
    "#Respective p values\n",
    "p_PBVSGS,p_PBVSTOT,p_GSVSTOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This was for the testing on the OCI description but we have it for the continuous so not really useful just dont wanna delete it\n",
    "stats.ttest_ind(PB_DF['oci_desc'].value_counts(),GS_DF['oci_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_LL['oci_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(PB_DF['oci_desc'].value_counts(),Final_LL['oci_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(GS_DF['oci_desc'].value_counts(),Final_LL['oci_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "A = OCI([2011])\n",
    "#\n",
    "A = A[2011]\n",
    "A['oci']=(pd.to_numeric(A['oci'],downcast='float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#T-TEST for the OCI of the MVA DF and The OCI of the OCI DF\n",
    "stats.ttest_ind(Final_LL['oci'],A['oci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
